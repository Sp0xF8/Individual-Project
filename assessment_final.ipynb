{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Individual Assesment - University of the West of England\n",
    "<a href=\"https://github.com/Sp0xF8/Individual-Project\">GitHub Project Link</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## These imports are shared across the whole application and not specific to either model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json \n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Imports\n",
    "<p>These imports are specifically related to the SVM's functionality</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADA Ensambles\n",
    "<p>These imports are specifically related to the ADA models</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Data ready for interperating\n",
    "<p>In this stage we are using the Pandas libary to load the CSV data file.</p>\n",
    "\t<div style=\"margin-left: 20px;\">\n",
    "\t\t<p>- This helps by giving us functionality to use a wide array of methods</p>\n",
    "\t</div>\n",
    "\t<p>The data is then printed to allow for easy refencing and understanding of base data</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "5            5      116             74              0        0  25.6   \n",
      "6            3       78             50             32       88  31.0   \n",
      "7           10      115              0              0        0  35.3   \n",
      "8            2      197             70             45      543  30.5   \n",
      "9            8      125             96              0        0   0.0   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.627   50        1  \n",
      "1                     0.351   31        0  \n",
      "2                     0.672   32        1  \n",
      "3                     0.167   21        0  \n",
      "4                     2.288   33        1  \n",
      "5                     0.201   30        0  \n",
      "6                     0.248   26        1  \n",
      "7                     0.134   29        0  \n",
      "8                     0.158   53        1  \n",
      "9                     0.232   54        1  \n",
      "(768, 9)\n"
     ]
    }
   ],
   "source": [
    "## Load the CSV file\n",
    "\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "print(data[:10])\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance of Splitting Test and Training Data in Machine Learning Models\n",
    "\n",
    "In Machine Learning, it is essential to split the dataset into training and test sets.\n",
    "<div style=\"margin-left: 20px;\">\n",
    "\t<p>The importance of having a <strong> Validation Dataset </strong> is to have a selection of data for which the learned model will be scored against. By knowing the result of said inputs, it is possible to match them against the predictions made by the model. This is the most accurate way to test. A counter-option would be to test against the trained data, however this wouldn't be a real-world example of predicting new labels. Knowing the success rate of predicted models means the model can be adjusted until the preformance is satisfactory. \n",
    "\t</p>\n",
    "</div>\n",
    "\n",
    "Additionally, the from the training <strong>data</strong> provided by the CSV, the outcome must be dropped for the list of inputs ($X$). Everything, besides the outcome, should also be dropped from the list of outputs ($y$).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the initial X and y lists from the data CSV file\n",
    "X = data.drop(\"Outcome\", axis=1)\n",
    "y = data[\"Outcome\"]\n",
    "\n",
    "\n",
    "#split the data into training and testing data, 80% training and 20% testing- random state is set to 42 because it is the answer to everything\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating SVM Variables\n",
    "These two variables are of the type Dictonary, which is similar in format to the <strong>Json</strong> file extension. Advantages of setting the models to work in this behavoiur include ease of access and increased readability. It also gives the ability to store mulitple different datatypes in one element and easily export it to a Json file.\n",
    "<div style=\"margin-left: 20px;\">\n",
    "\t<p>\n",
    "\t\t<strong>svm_tests</strong> \t\t\t: This Dictonary is used to store the range of hyper-paramaters passed to the depth first grid search.\n",
    "\t</p>\n",
    "\t<p>\n",
    "\t\t<strong>current_svm_data</strong> \t: This Dictionary is used to store the current hyper-paramaters being passed to the <strong>svm_model</strong> class.\n",
    "\t</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store the tests which will be preformed on the SVM\n",
    "svm_tests = {\n",
    "\t'C': [7, 9, 11],\n",
    "\t'tollerance': np.linspace(0.0001, 0.1, 100),\n",
    "\t'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "\t'max_iter': np.linspace(10, 10000, 100).astype(int),\n",
    "\t'decision_function_shape': ['ovo', 'ovr'],\n",
    "\t'possibility': [True, False],\n",
    "}\n",
    "\n",
    "# Dictionary to store the current test's data for the SVM\n",
    "current_svm_data = {\n",
    "\t'kernel': None,#\n",
    "\t'max_iter': None,\n",
    "\t'decision_function_shape': None,#\n",
    "\t'probability': None,#\n",
    "\t'shrinking': None,#\n",
    "\t'C': None,\n",
    "\t'tollerance':None#\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Ensambles Variables\n",
    "\n",
    "\n",
    "Simiarly to the previous definitions, these variables are also of the type Dictionary. They are, instead, however multi-layered. \n",
    "<div style=\"margin-left: 20px;\">\n",
    "\t<p>\n",
    "\t\t<strong>ada_ensambles_tests</strong> : This Dictonary is used to store the range of hyper-paramaters passed to the depth first grid search.\n",
    "\t\t<div style=\"margin-left: 50px;\">\n",
    "\t\t\t<p>\n",
    "\t\t\t\t<strong>Estimator</strong> \t\t\t: This Dictonary is used to store the range of hyper-paramaters passed to the <strong>Random Forest Classifier</strong>.\n",
    "\t\t\t</p>\n",
    "\t\t\t<p>\n",
    "\t\t\t\t<strong>Params</strong> \t\t\t: This Dictionary is used to store the range of hyper-paramaters passed to the <strong>Ada Boost classifier</strong>.\n",
    "\t\t\t</p>\n",
    "\t\t</div>\n",
    "\t</p>\n",
    "\t<hr style=\"width:75%;\" align=\"left\">\n",
    "\t<p>\n",
    "\t\t<strong>current_ada_data</strong> \t: This Dictionary is used to store the current hyper-paramaters being passed to the <strong>ada_model</strong> class.\n",
    "\t\t<div style=\"margin-left: 50px;\">\n",
    "\t\t\t<p>\n",
    "\t\t\t\t<strong>Estimator</strong> \t\t\t: This Dictonary is used to store the current hyper-paramaters being passed to the <strong>Random Forest Classifier</strong>.\n",
    "\t\t\t</p>\n",
    "\t\t\t<p>\n",
    "\t\t\t\t<strong>Params</strong> \t\t\t: This Dictionary is used to store the current hyper-paramaters being passed to the <strong>Ada Boost classifier</strong>.\n",
    "\t\t\t</p>\n",
    "\t\t</div>\n",
    "\t</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store the tests which will be preformed on the AdaBoost Classifier and Random Forest Classifier\n",
    "ada_ensambles_tests = {\n",
    "\t'Estimator': {\n",
    "\t\t'n_estimators': np.linspace(1, 200, 10).astype(int),\n",
    "\t\t'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "\t\t'max_features': ['sqrt', 'log2'],\n",
    "\t\t'bootstrap': [True, False],\n",
    "\t\t'min_samples_split': np.linspace(2, 11, 10).astype(int),\n",
    "\t\t'min_samples_leaf': np.linspace(2, 6, 5).astype(int)\n",
    "\t},\n",
    "\t'Params': {\n",
    "\t\t'n_estimators': np.linspace(1, 100, 10).astype(int),\n",
    "\t\t'learning_rate': np.linspace(0.1, 3, 10),\n",
    "\t\t'algorithim': ['SAMME']\n",
    "\t}\n",
    "}\n",
    "\n",
    "# Dictionary to store the current test's data for the AdaBoost Classifier and Random Forest Classifier\n",
    "current_ada_data = {\n",
    "\t'Estimator': {\n",
    "\t\t'n_estimators': None,\n",
    "\t\t'criterion': None,\n",
    "\t\t'max_features': None,\n",
    "\t\t'bootstrap': None,\n",
    "\t\t'min_samples_split': None,\n",
    "\t\t'min_samples_leaf': None\n",
    "\t},\n",
    "\t'Params': {\n",
    "\t\t'n_estimators': None,\n",
    "\t\t'learning_rate': None,\n",
    "\t\t'algorithim': None\n",
    "\t}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the test comparison\n",
    "These two vairables are of type List and are used to store the best solutions found and their respective metrics. This is essneital in preforming a goal orientated depth first search. Without having a comparison, how can you know if you are finding a better solution?\n",
    "\n",
    "<div style=\"margin-left: 20px;\">\n",
    "\t<p>\n",
    "\t\t<strong>solution_list</strong> \t\t: This List stores class objects of the top 10 solutions, allowing for instant referencing once the search has been completed.\n",
    "\t</p>\n",
    "\t<p>\n",
    "\t\t<strong>accuracy_list</strong> \t\t: This List stores the accuracy of the class object at the same offset and is the list used for direct comparison without having to reference the solutions list; slowing down the, already hundreds of thousands, of tests. \n",
    "\t</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_list = []\n",
    "accuracy_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ratios Function\n",
    "This function is an easy way of returning multiple metrics in a more efficent way: using far less function calls.\n",
    "\n",
    "### Paramaters:\n",
    "\n",
    "<div style=\"margin-left: 20px;\">\n",
    "\t<p>\n",
    "\t\t<strong>y_true</strong> \t\t: This variable is of type numpy array and holds the actual true values for the test data (<strong>y_test</strong>)\n",
    "\t</p>\n",
    "\t<p>\n",
    "\t\t<strong>y_pred</strong> \t\t: This variable is also of type numpy array and holds the predicted values for the test data (<strong>y_test</strong>)\n",
    "\t</p>\n",
    "</div>\n",
    "\n",
    "### Prediction Types:\n",
    "\n",
    "<div style=\"margin-left: 20px;\">\n",
    "\t<p>\n",
    "\t\t<strong>True Positive</strong> \t\t: This type of classification occurs when the model <em><strong>predicts a Positive result</strong>, and the result is <strong>actually Positive</strong></em>.\n",
    "\t</p>\n",
    "\t<p>\n",
    "\t\t<strong>True Negative</strong> \t\t: This type of classification occurs when the model <em><strong>predicts a Negative result</strong>, and the result is <strong>actually Negative</strong></em>.\n",
    "\t</p>\n",
    "\t<p>\n",
    "\t\t<strong>False Positive</strong> \t: This type of classification occurs when the model <em><strong>predicts a Positive result</strong>, and the result is <strong>actually Negative</strong></em>.\n",
    "\t</p>\n",
    "\t<p>\n",
    "\t\t<strong>False Negative</strong> \t: This type of classification occurs when the model <em><strong>predicts a Negative result</strong>, and the result is <strong>actually Positive</strong></em>.\n",
    "\t</p>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funct to test the SVM model without calling different functions, this is to make the code more readable and efficient\n",
    "def ratios(y_true, y_pred):\n",
    "    ## Get the confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "    \n",
    "    ## Calculate False Negative Ratio\n",
    "    fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "    \n",
    "\t## Calculate Recall\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    \n",
    "\t## Calculate Precision\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    \n",
    "\t## Calculate specificity\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    \n",
    "    return fnr, recall, precision, specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Definitions\n",
    "\n",
    "Using a class instead of a standard function is highly effiecent. It allows for better reuseability, and storage, of data in the long term. This is fundamental concept of Object Orientated Programming. By using OOP in this project, it is much easier to rapidly cycle through a grid of hyper paramaters and subsequently output and results gained. This also means that less indents are reuqired to accomplish the same task, resulting in cleaner code which is much easier to understand.\n",
    "\n",
    "By choosing to use a class, there is inherent access to standardised methods: like the constructor. Both the **svm_model** and **ada_model** both use **constructurs** which accept only one paramater. These are the previously defined respective Dictionarys (**current_svm_data**, **current_ada_data**). In this regard, the constructor is used to not only setup the Machine Learning model but also used to save paramaters. These can later be referenced by a different function, printing the best solutions found by the search. \n",
    "\n",
    "Additionally, the **predict** method is shared between the classes. While they both have vastly different features, they return the same metric values. The models themselves are stored in function-local variables, meaning once the predictions have been made: they are destroyed, freeing memory. The metric data is then stored in appropriatly named class-vairables for later use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric Variables:\n",
    "\n",
    "<div style=\"margin-left: 20px;\">\n",
    "\t<p>\n",
    "\t\t<strong>closed_pred</strong> \t\t: This is a variable of type Numpy Array and holds the <em>predicted true values for the test data</em> (<strong>y_pred</strong>)\n",
    "\t</p>\n",
    "\t<p>\n",
    "\t\t<strong>closed_accuracy</strong> \t: This variable is of the type Float and holds the most simple of the metrics. This is simply the number of <em>correctly classafied datapoints to the number of incorrectly classafied datapoints</em>. Having a good overall accuracy is important but, dependant on what application the model is used for, can be misappropriated.\n",
    "\t</p>\n",
    "\t<p>\n",
    "\t\t<strong>closed_precision</strong> \t: This variable is also of type Float and holds a ratio of <em>correctly identified <strong>True Positives</strong> to the total number of positive predictions</em> made by the model. This is useful for analysing the validity of the positivly predicited models. \n",
    "\t</p>\n",
    "\t<p>\n",
    "\t\t<strong>closed_specificity</strong> : Similar to <strong>closed_precision</strong>, this variable is also Float. Instead, however, it stores the ratio of <em>correctly identified <strong>True Negatives</strong> to the total number of negative predictions</em> made by the model.  \n",
    "\t</p>\n",
    "\t<p>\n",
    "\t\t<strong>closed_recall</strong> \t\t: This variable type of Float is used for the <em><strong>Recall</strong>, or <strong>Sensitivity</strong>,</em> of the models predictions. This is <em>the number of <strong>True Positive</strong> predictions to the total number of positive instances</em>. Recall makes excellent pairing if <strong>closed_precision</strong> is also a metric of choice. It helps to give more complete info, as precision wil not specify how many instances were missed: only how accurate it is at finding positive predicitions. This could be misleading, as an easy way to always predict people with diabeties, without missing anyone, is to simply say <em>everyone has diabeties</em>. This would <strong><em>never miss a diabetic</strong>, but would <strong>instantly slow down formal diagnosis</strong> because everyone would be referred</em>.\n",
    "\t</p>\n",
    "\t<p>\n",
    "\t\t<strong>closed_fnr</strong> \t\t: This variable is of type float and holds the <em><strong>False Negative Ratio</strong></em>. This the invserse of <strong>Recall</strong>, however, for transparancy, using this as a clear metric seemed preferable. Often refered to as the <em>miss rate</em>, this metric is highly valued when missed positive instances is critical. When dealing with any form of diagnosis, it is far more important that the model can correctly identify as many <strong>True Positives</strong> as possible. <em>While it is <strong>less than ideal if a non-diabetic is referred</strong>, this would cause the diagnosis system to slow down, it is <strong>far more important that the diabetic is not overlooked</strong> and left without treatment</em>. It is important to note that <strong>this should not be the only metric used for judgement</strong>. A good choice of pairing for this metric would also be <em>Precision or Specificity</em>. Specificity would provide a well rounded overview by providing insight into if the model is simply predicting everyone as diabetic. \n",
    "\t</p>\n",
    "\t<p>\n",
    "\t\t<strong>closed_f1</strong> \t\t\t: Of type Float, this variable stores the <em>harmonic mean of <strong>precision and recall</strong></em>. This ensures <strong>False Positives</strong> and <strong>False Negatives</strong> are accounted for, and is <em>particularly useful when neither have signifigantly different levels of importance</em>. Given the models previously stressed importance of not allowing for False Negatives, but having some leverage on False Positives: F1 scoring metrics are not entirely relavent. \n",
    "\t</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### svm_model.predict Method\n",
    "\n",
    "Typically, a prediction function would allow for some way of dynamically setting the data to be predicted. However, given the time complexity of the grid searches employed, it was far more efficent to define the test data globally and reference when needed. If this was to be progressed further, the predict function would need to take a multi-dimensional array as the input (representing the data to classify). For the current scenario, it is suited perfectly and offers an optimised solution.\n",
    "\n",
    "Inside the prediction function, it begins by defining a pipline; through which, the data should be processed before reaching the **Support Vector Classifier**. Given the type of model, and the large separation of the data (*e.g pregnancies: 1, glocouse: 168), the data must be pre-processed before it can be accuratly analysed by the **SVC**. Problems can easily arise in the effectiveness of Linear based algorithms, this is where the **StandardScaler** is useful inside the pipline. Instead of predefining the the patient data (**X_train**, **X_test**, ...) after having been scaled, causing disruptions to the other ML model (**ada_model**), the data is scaled on access of the model. This means new test data added will also not need to be scaled, as the pipline will automatically handle any scaling needs. \n",
    "\n",
    "\tclosed_clf.fit(X_train, y_train)\n",
    "\n",
    "This line of code is where the SVC Pipline is called to train the model. The first paramater, **X_train**, is then passed through the pipline. First being scaled, reducing the variance in the source data, then being passed further down the pipline to the SVC model and specified kernel. At its root, the **Standard Scaler** function is designed to help convert values from different formats into a single scale. It is designed to ensure that each feature has a mean of 0 and a unit of standard deviation. This is useful for Kernels such as *RBF*, which assumes that all features are centered around a 0 origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SVM Model Definition\n",
    "class svm_model:\n",
    "\n",
    "\t## Constructor - Takes in a data dictionary (current_svm_test) and assigns the values to the class variables\n",
    "\tdef __init__(self, data):\n",
    "\t\tself.kernel \t\t\t\t\t= data['kernel']\n",
    "\t\tself.max_iter \t\t\t\t\t= data['max_iter']\n",
    "\t\tself.func_shape \t\t\t\t= data['decision_function_shape']\n",
    "\t\tself.probability \t\t\t\t= data['probability']\n",
    "\t\tself.shrinking \t\t\t\t\t= data['shrinking']\n",
    "\t\tself.tollerance \t\t\t\t= data['tollerance']\n",
    "\t\tself.C \t\t\t\t\t\t\t= data['C']\n",
    "\n",
    "\n",
    "\n",
    "\t## Predict Function - Uses the current_svm_test from the constructor to create a pipeline and predict the outcome of the test data \n",
    "\tdef predict(self):\n",
    "\n",
    "\t\t### Create the pipeline as a local variable\n",
    "\t\tclosed_clf = make_pipeline(\t\n",
    "\t\t\t\t\t\t\t\t\tStandardScaler(), # Standardise the data before training\n",
    "\t\t\t\t\t\t\t\t\tSVC( # Create the SVC model with the given parameters from the current_svm_test dictionary\n",
    "\t\t\t\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t\t\t\tkernel=self.kernel, \n",
    "\t\t\t\t\t\t\t\t\t\tmax_iter=self.max_iter, \n",
    "\t\t\t\t\t\t\t\t\t\tdecision_function_shape=self.func_shape, \n",
    "\t\t\t\t\t\t\t\t\t\tprobability=self.probability, \n",
    "\t\t\t\t\t\t\t\t\t\tshrinking=self.shrinking,\n",
    "\t\t\t\t\t\t\t\t\t\tC=self.C,\n",
    "\t\t\t\t\t\t\t\t\t\ttol=self.tollerance\n",
    "\t\t\t\t\t\t\t\t\t)\n",
    "\t\t\t\t\t\t\t\t)\n",
    "\t\t\n",
    "\t\t### Fit the model to the training data \n",
    "\t\tclosed_clf.fit(X_train, y_train)\n",
    "\n",
    "\t\t### Predict the outcome of the test data\n",
    "\t\tself.closed_pred \t\t= closed_clf.predict(X_test)\n",
    "\n",
    "\t\t### Calculate the accuracy, f1 score, false negative rate, recall, precision, and specificity of the model\n",
    "\t\tself.closed_accuracy \t= accuracy_score(y_test, self.closed_pred)\n",
    "\t\tself.closed_f1 \t\t\t= f1_score(y_test, self.closed_pred)\n",
    "\t\t\n",
    "\t\tself.closed_fnr, self.closed_recall, self.closed_precision, self.closed_specificity\t= ratios(y_test, self.closed_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ada_model.predict Method\n",
    "\n",
    "### Random Forest Classifier\n",
    "\tclosed_hype_clf = RandomForestClassifier(...)\n",
    "\n",
    "1. At its basics, **Random Forest Classifier** is a combination of multiple decision trees, all trained from a different *randonly selected* datapoint. This simply involves choosing multiple random samples from the origonal dataset. These samples are then used to build trees from. \n",
    "\n",
    "2. At *each node of each decision tree*, a random number of features is selected (*so long as the value doesnt exceed **max_features***). This helps to ensure decision trees do not run in parralel, defeating the purpose of multiple trees. \n",
    "\n",
    "3. After a node has selected its features, within these selected features: the one which provides the best split, *according to the **criterion***, is chosen. \n",
    "\n",
    "4. The remaining data is then split into subsets based on the selected feature, creating different branches on the tree. This process is then repeated at each node until a stopping crietia is met.\n",
    "\n",
    "5. After growing ***n_estimator*** number of trees, the results are aggrogated to make predictions. When these predicitons are made, each tree independently makes their own prediction. The final prediction for the *new input data, **X_test**, is the **average result of all of the trees***. \n",
    "\n",
    "### AdaBoost Classifier\n",
    "\tclosed_clf = AdaBoostClassifier(closed_hype_clf, ...)\n",
    "\n",
    "When you pass a Random Forest Classifier as an estimator to an AdaBoost Classifier, the AdaBoost algorithm works in conjunction with the Random Forest base estimator to create a strong ensamble model. Here's how it works:\n",
    "\n",
    "1. The Random Forest Classifier is initialized as the base estimator within the AdaBoost. AdaBoost uses the Random Forest Classifier to build a sequence of weak learners.\n",
    "\n",
    "2. AdaBoost trains multiple instances of the Random Forest Classifier, focusing more on the entities that were misclassified by the previous learners. This is achieved by adjusting the weights of the training entities during each iteration.\n",
    "\n",
    "3. After training multiple Random Forest models, AdaBoost combines their predictions using a weighted voting system. The final prediction is determined from the weighted sum of individual Random Forest predictions, where the weight assigned to each model depends on its performance during training.\n",
    "\n",
    "4. By iteratively focusing on difficult-to-classify entities and combining the predictions of multiple Random Forest models, AdaBoost enhances the overall performance of the ensamble classifier. This results in a robust and accurate model that utalises the strengths of both AdaBoost and Random Forest Classifiers.\n",
    "\n",
    "\n",
    "As previously mentioned, data only needs to be scaled for models which assume the data is centered around a 0 point. Neither of these classifiers do, meaning the data can be left in its standard form. This is because they make choices based on relative values, not absolute. As mentioned, they choose splits which maximise information gain: but the splits are made independently within features, meaning no scale conflicts either.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SVM Model Definition\n",
    "class ada_model:\n",
    "\n",
    "\t## Constructor - Takes in a data dictionary (current_svm_test)\n",
    "\tdef __init__(self, current_test):\n",
    "\n",
    "\t\t## Assign the values from the current_test dictionary to the class variables, which are also dictionaries. this removes the outer layer, improving readability later on\n",
    "\t\tself.clf_estimator = current_test['Estimator']\n",
    "\n",
    "\t\tself.clf_params = current_test['Params']\n",
    "\t\t\n",
    "\n",
    "\t## Predict Function - Uses the current_svm_test from the constructor to create an AdaBoost Classifier and a Random Forest Classifier to be used as an estoimator to predict the outcome of the test data\n",
    "\tdef predict(self):\n",
    "\n",
    "\t\t### Create the estoimator for the AdaBoost Classifier as a local variable \n",
    "\t\tclosed_hype_clf = RandomForestClassifier(\n",
    "\t\t\t\t\t\t\t\t\tn_estimators=self.clf_estimator['n_estimators'], \n",
    "\t\t\t\t\t\t\t\t\tcriterion=self.clf_estimator['criterion'],\n",
    "\t\t\t\t\t\t\t\t\tmax_features=self.clf_estimator['max_features'], \n",
    "\t\t\t\t\t\t\t\t\tbootstrap=self.clf_estimator['bootstrap'],\n",
    "\t\t\t\t\t\t\t\t\tmin_samples_split=self.clf_estimator['min_samples_split'], \n",
    "\t\t\t\t\t\t\t\t\tmin_samples_leaf=self.clf_estimator['min_samples_leaf'], \n",
    "\t\t\t\t\t\t\t\t\tn_jobs=-1\n",
    "\t\t\t\t\t\t\t\t)\n",
    "\t\t\t\n",
    "\t\t### Create the AdaBoost Classifier as a local variable with the given parameters from the current_svm_test dictionary\n",
    "\t\tclosed_clf = AdaBoostClassifier(\n",
    "\t\t\t\t\t\t\tclosed_hype_clf,\n",
    "\t\t\t\t\t\t\tn_estimators=self.clf_params['n_estimators'],\n",
    "\t\t\t\t\t\t\tlearning_rate=self.clf_params['learning_rate'],\n",
    "\t\t\t\t\t\t\talgorithm=self.clf_params['algorithim'],\n",
    "\t\t\t\t\t\t\trandom_state=1)\n",
    "\t\t\n",
    "\t\t### Fit the model to the training data\n",
    "\t\tclosed_clf.fit(X_train, y_train)\n",
    "\n",
    "\t\t### Predict the outcome of the test data\n",
    "\t\tself.closed_pred \t\t= closed_clf.predict(X_test)\n",
    "\n",
    "\t\t### Calculate the accuracy, f1 score, false negative rate, recall, precision, and specificity of the model\n",
    "\t\tself.closed_accuracy \t= accuracy_score(y_test, self.closed_pred)\n",
    "\t\tself.closed_f1 \t\t\t= f1_score(y_test, self.closed_pred)\n",
    "\t\tself.closed_fnr, self.closed_recall, self.closed_precision, self.closed_specificity\t= ratios(y_test, self.closed_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Serialisable\n",
    "This simple helper function takes an entity as a paramater and returns it, after having been converted to a JSON serialisable type. Given the only abstract type being used is a **Numpy Int32**, there only needs to be one conditional. Every other type can be converted at base value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_serialisable(ent):\n",
    "    if isinstance(ent, np.int32):\n",
    "        return int(ent)\n",
    "    return ent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write JSON\n",
    "\n",
    "While it would have been entirely possible to use the the classes default __dict__ function, this gives little control over the how the results are displayed: decreasing readabaility. It is true, given the JSON file extnesion, the data could simply be extracted and accessed in a more appropriate way. But it made more sense to provide a file that is also legible to a human aswel. This means that the user could quickly take a look at the results manually, without having to decypher the cryptic positioning of the variables within the dictionary.\n",
    "\n",
    "Additionally, it would have also been possible to store the array as an array. However, given the length of the array: it seemed more logical to include it as a string, creating a row instead of a 100 line column. This also makes direct comparison between predictions and expected results much easier as they run in paralel.\n",
    "\n",
    "#### Paramaters:\n",
    "<div style=\"margin-left: 20px;\">\n",
    "\t<p>\n",
    "\t\t<strong>class_name</strong> \t\t: This paramater should either be an <strong>svm_model</strong> or <strong>ada_model</strong>. \n",
    "\t</p>\n",
    "\t<p>\n",
    "\t\t<strong>output_file</strong> \t\t: This paramater should be of type <strong>string</strong> and <em>finish with a \".json\" file extension</em>. It will not create an error if a txt is used, but some json functionality could be limited.\n",
    "\t</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(class_name, output_file):\n",
    "\t\n",
    "\t## Create a dictionary to store the class variables and the results of the model\n",
    "\tclass_dict = {\n",
    "\t\t\"features\": {# Dictionary created empty, to be filled with the features of corresponding model.\n",
    "\t\t},\n",
    "\t\t\"results\": { # Dictionary used to store the metrics of the model \n",
    "\t\t\t\"accuracy\": class_name.closed_accuracy,#float\n",
    "\t\t\t\"f1\": class_name.closed_f1,#float\n",
    "\t\t\t\"fnr\": class_name.closed_fnr,#float\n",
    "\t\t\t\"recall\": class_name.closed_recall,#float\n",
    "\t\t\t\"precision\": class_name.closed_precision,#float\n",
    "\t\t\t\"specificity\": class_name.closed_specificity#float\n",
    "\t\t},\n",
    "\t\t\"predictions\": { # Dictionary used to store the predictions of the model\n",
    "\t\t\t\"y_pred\": str(class_name.closed_pred.tolist()),#array as string\n",
    "\t\t\t\"y_true\": str(y_test.tolist())#array as string \n",
    "\t\t}\n",
    "\t}\n",
    "\n",
    "\t## Check if the class_name is an instance of the svm_model class\n",
    "\tif(isinstance(class_name, svm_model)):\n",
    "\t\tclass_dict[\"features\"] = { # If the class_name is an instance of the svm_model class, fill the features dictionary with the features of the model\n",
    "\t\t\t\"kernel\": str(class_name.kernel),#str\n",
    "\t\t\t\"max_iter\": class_name.max_iter,#int\n",
    "\t\t\t\"decision_function_shape\": str(class_name.func_shape),#str\n",
    "\t\t\t\"probability\": class_name.probability,#bool\n",
    "\t\t\t\"shrinking\": class_name.shrinking,#bool\n",
    "\t\t\t\"tollerance\": class_name.tollerance,#float\n",
    "\t\t\t\"C\": class_name.C#float\n",
    "\t\t}\n",
    "\telif(isinstance(class_name, ada_model)):\n",
    "\t\tclass_dict[\"features\"] = { # If the class_name is an instance of the ada_model class, fill the features dictionary with the features of the model\n",
    "\t\t\t\"Estimator\": {\n",
    "\t\t\t\t\"n_estimators\": class_name.clf_estimator['n_estimators'],#int\n",
    "\t\t\t\t\"criterion\": str(class_name.clf_estimator['criterion']),#str\n",
    "\t\t\t\t\"max_features\": str(class_name.clf_estimator['max_features']),#str\n",
    "\t\t\t\t\"bootstrap\": class_name.clf_estimator['bootstrap'],#bool\n",
    "\t\t\t\t\"min_samples_split\": class_name.clf_estimator['min_samples_split'],#int\n",
    "\t\t\t\t\"min_samples_leaf\": class_name.clf_estimator['min_samples_leaf']#int\n",
    "\t\t\t},\n",
    "\t\t\t\"Params\": {\n",
    "\t\t\t\t\"n_estimators\": class_name.clf_params['n_estimators'],#int\n",
    "\t\t\t\t\"learning_rate\": class_name.clf_params['learning_rate'],#float\n",
    "\t\t\t\t\"algorithim\": str(class_name.clf_params['algorithim'])#str\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\n",
    "\t_tojson_ = json.dumps(class_dict, default=convert_to_serialisable, indent=4) # Convert the class_dict to a JSON string\n",
    "\n",
    "\twith open(output_file, 'a') as f: # Open the output file in append mode and write the JSON string to the file\n",
    "\n",
    "\t\tf.write(str(_tojson_ ) + ',\\n') # Add a comma and a newline character to the end of the JSON string to separate the different tests\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Comparison\n",
    "\n",
    "This is quite a simple function. It checks that **INSERTMETRICNAME** is higher than 70%, then proceeds to compare the current test against the current Top 10 solutions found. If a new best solution is found, the **solution_list** and **accuracy_list** are appended respectivly. The solution is then written to the correctly named JSON file. If the length of the list exceeds 10 items, the item at the front of the list is removed. \n",
    "\n",
    "#### Paramaters:\n",
    "<div style=\"margin-left: 20px;\">\n",
    "\t<p>\n",
    "\t\t<strong>current_test</strong> \t: This paramater should either be an <strong>svm_model</strong> or <strong>ada_model</strong>. \n",
    "\t</p>\n",
    "\t<p>\n",
    "\t\t<strong>solution_name</strong> \t: This paramater should be of type <strong>string</strong> and <em>finish with a \".json\" file extension</em>. It will not create an error if a txt is used, but some json functionality could be limited.\n",
    "\t</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_worst(current_test, solution_name):\n",
    "\n",
    "\tif (current_test.closed_precision < 0.7):\n",
    "\t\treturn\n",
    "\n",
    "\t## for each solution in the solution list, where i stores the current solution being compared to the current test\n",
    "\tfor i in range(len(solution_list)):\n",
    "\n",
    "\t\t## cbeck if the current test's preformance metric is more optimal than the current solution's preformance metric\n",
    "\t\tif (current_test.closed_fnr < accuracy_list[i] or current_test.closed_fnr < 0.34):\n",
    "\t\t\t## append the current test to the solution list and the accuracy of the current test to the accuracy list\n",
    "\t\t\tsolution_list.append(current_test)\n",
    "\t\t\taccuracy_list.append(current_test.closed_fnr)\n",
    "\n",
    "\t\t\t## write the current test to the output file\n",
    "\t\t\twrite_json(current_test, solution_name)\n",
    "\n",
    "\n",
    "\t\t\t## check if the length of the solution list is greater than 10\n",
    "\t\t\tif(len(solution_list) > 10):\n",
    "\t\t\t\t## pop the first element from the solution list and the accuracy list\n",
    "\t\t\t\tsolution_list.pop(0)\n",
    "\t\t\t\taccuracy_list.pop(0)\n",
    "\n",
    "\t\t\treturn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Systematic Grid Search\n",
    "\n",
    "**SKLearn** deos include a standard grid search function: *GridSearchCV*. It is described as an \"*exhaustive* search\" over a definied paramater list. First it trains each possibility of **hyperparamaters** and scores them, using the most admirable for the final predictions. This function is ***increably exhaustive*** when searching over a large dataset. Instead of preforming an optimised search, this algorithm aims to save all possibilities in memory. This would be insignifigant when only checking a few hundred tests. However, with the hundreds of millions of combinations: **how do you know which to test**? \n",
    "\n",
    "It is possible to use the GridSearchCV function for these millions of test paramaters, however the computational requirements are *linear to the **number of tests** $*$ **memory usage for the model selected***. This can easily cause any computer to come to a grinding hault and freeze, even possibly resulting in a BSOD error. The *optimal memory usage should be **memory usage for the model selected** $*$ **number of best solutions***. For this search, as seen in the *Comparison Function*, the max number of best solitions to be stored in active memory should not exceed the number of best solutions, *10*, and an additional solution for the one being tested. This gives a *final memory usage of **11** $*$ **memory usage for the model selected***.\n",
    "\n",
    "Given the memory optimisation of the custom search functions, it would be possible to preform searches on computers with limited memory availability. Dependent on the speed of the computer, and the size of the test, this could still take days to analyse for the most optimal hyperparamaters: however, in theory it should only need to run once as all best solutions found are stored in an external data-structure. **More will be spoken about that later**, but the key benefits of searching in this style is that it gives *functionalty to find the best paramaters inside of an **infinitly large pool of paramaters***. That is, ***so long as you have enough time to wait***. \n",
    "\n",
    "This is a deal breaker for the health industry, whos computer power usually lags behind civilisation due to lack of funding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Functions\n",
    "\n",
    "Both of these functions are structured in the same way for simplistic calling conventions, they also use the same logic: giving exceptions for differences needed by the individual model.\n",
    "\n",
    "Whent he function is called, a few new *local varaibles* are defined. **iterationCount** is inconsequential to the flow of the actual search, however does it allows the program operator to see how many tests have been completed. This is used in combination with the **number_of_tests** constant, which is calculated by multiplying the length of all of the hyper paramater arrays together. These are later used to give a direct number of tests remaining, affirming to the operator: *tests are still being executed*. \n",
    "\n",
    "Next, the **Best Solutions** output is prepared. A new file is created in the JSON file format and a singular bracket and newline is written. This allows the different, best solutions, to be indexed and referenced as independent dictionarys. The final stage of preperation occurs when pushing an empty solution and the worst possible score for the model to acheive. This kick-starts the solution comparison, without it there is nothing to compare against and nothing to iterate. Because this data is added to the respective lists directly, there they will not be outputted to the **Best Solutions**. Neither will they be output to the **Best 10 Solutions**, the first few tests will overwite them no *matter how good they actually are*: the initial push is relativly much worse.\n",
    "\n",
    "Finally, the bullk of the functions. Both are rooted on the principle: multiple nested for loops, incrementally cycling through the test paramaters held by **data**. These values are passed to the relative model's dictionary which is then subsequently passed to the class instance reprenting the Machine Learning model chosen. The prediction function is then called, on termination the class is passed to the *Comparison Function*. \n",
    "\n",
    "On completion of each itteration, an addition macro is applied to the **iterationCount** variable so that the completion percentage of the search can be accuratly seen. Every time the algorithm completes one inner loop: the **Iterations** TXT is overwritten.\n",
    "\n",
    "Once the entire search as been completed, a final closing bracket is added to the **Best Solutions**. Finally, the **Best 10 Solutions** are produced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paramaters:\n",
    "<div style=\"margin-left: 20px;\">\n",
    "\t<p>\n",
    "\t\t<strong>data</strong> \t: This paramater should be of type Dictionary and should hold the <strong>svm_tests</strong>, or <strong>ada_ensambles_tests</strong>. \n",
    "\t</p>\n",
    "</div>\n",
    "\n",
    "### Outputs:\n",
    "<div style=\"margin-left: 20px;\">\n",
    "\t<p>\n",
    "\t\t<strong>Best Results</strong> \t: This output will be in the JSON file format and <em>will be generated, <strong>only  on completion of the entire search</strong></em>.\n",
    "\t</p>\n",
    "\t<p>\n",
    "\t\t<strong>Results</strong> \t: This output will be in the JSON file format and <em>will be appended <strong>every time a new best solution is found</strong></em>.\n",
    "\t</p>\n",
    "\t<p>\n",
    "\t\t<strong>Iterations</strong> \t: This output will be in the TXT file format and <em>will be overwirtten <strong>every few hundred test solutions</strong></em>.\n",
    "\t</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform a depth first search on the SVM model\n",
    "def svmDepthFirstSearch(data):\n",
    "\n",
    "\t## Clear the solution list and the accuracy list\n",
    "\tsolution_list.clear()\n",
    "\taccuracy_list.clear()\n",
    "\n",
    "\t## Create a variable to store the number of tests that have beeb preformed\n",
    "\titerationCount = 0\n",
    "\n",
    "\t## Calculate the number of tests that will be preformed\n",
    "\tnumber_of_tests = (\n",
    "\t\tlen(data['kernel']) *\n",
    "\t\tlen(data['decision_function_shape']) *\n",
    "\t\tlen(data['possibility']) *\n",
    "\t\tlen(data['possibility']) *\n",
    "\t\tlen(data['max_iter']) *\n",
    "\t\tlen(data['tollerance']) *\n",
    "\t\tlen(data['C'])\n",
    "\t)\n",
    "\n",
    "\n",
    "\t## Setupt the svm_results.json file to store the best solutions discovered by the tests\n",
    "\twith open(\"svm_results.json\", 'w') as f:\n",
    "\t\t## write the opening square bracket to the file to start the JSON array \n",
    "\t\tf.write(\"[\\n\")\n",
    "\t\n",
    "\n",
    "\t## Append an empty object to the solution list and set the accuracy to the worst possible metric score\n",
    "\tsolution_list.append(current_svm_data)\n",
    "\taccuracy_list.append(1.0)\n",
    "\n",
    "\t## Itterate through the different parameters in the data dictionary\n",
    "\tfor kernel in data['kernel']:\n",
    "\t\tfor function_shape in data['decision_function_shape']:\n",
    "\t\t\tfor probability in data['possibility']:\n",
    "\t\t\t\tfor shrinking in data['possibility']:\n",
    "\t\t\t\t\tfor max_iter in data['max_iter']:\n",
    "\t\t\t\t\t\tfor tol in data['tollerance']:\n",
    "\t\t\t\t\t\t\tfor C in data['C']:\n",
    "\n",
    "\t\t\t\t\t\t\t\t## Set the current_svm_data dictionary to the current parameters indexed by the loop\n",
    "\t\t\t\t\t\t\t\tcurrent_svm_data['kernel'] = kernel\n",
    "\t\t\t\t\t\t\t\tcurrent_svm_data['decision_function_shape'] = function_shape\n",
    "\t\t\t\t\t\t\t\tcurrent_svm_data['probability'] = probability\n",
    "\t\t\t\t\t\t\t\tcurrent_svm_data['shrinking'] = shrinking\n",
    "\t\t\t\t\t\t\t\tcurrent_svm_data['max_iter'] = max_iter\n",
    "\t\t\t\t\t\t\t\tcurrent_svm_data['tollerance'] = tol\n",
    "\t\t\t\t\t\t\t\tcurrent_svm_data['C'] = C\n",
    "\n",
    "\n",
    "\t\t\t\t\t\t\t\t## Create a new instance of the svm_model class with the current_svm_data dictionary\n",
    "\t\t\t\t\t\t\t\tcurrent_test = svm_model(current_svm_data)\n",
    "\n",
    "\t\t\t\t\t\t\t\t## Call the predict method of the current_test instance\n",
    "\t\t\t\t\t\t\t\tcurrent_test.predict()\n",
    "\t\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t\t## Preform a comparison check\n",
    "\t\t\t\t\t\t\t\tcheck_worst(current_test, \"svm_results.json\")\n",
    "\n",
    "\t\t\t\t\t\t\t\t## Increment the iteration count\n",
    "\t\t\t\t\t\t\t\titerationCount += 1\n",
    "\t\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t## Write the current iteration count to the file to keep track of the progress EVERY TIME THE TOLLERANCE IS CHANGED\n",
    "\t\t\t\t\t\twith open(\"svm_iterations.txt\", 'w') as f:\n",
    "\t\t\t\t\t\t\tf.write(\"Iteration: \" + str(iterationCount) + \"/\" + str(number_of_tests))\n",
    "\n",
    "\n",
    "\t## Write the closing square bracket to the file to end the JSON array\n",
    "\twith open(\"svm_results.json\", 'a') as f:\n",
    "\t\tf.write(\"]\\n\")\n",
    "\n",
    "\n",
    "\t## Write the best solutions to the output file\n",
    "\t\t\n",
    "\twith open(\"svm_best_results.json\", 'w') as f:\n",
    "\t\tf.write(\"[\\n\")\n",
    "\n",
    "\tfor i in range(len(solution_list)):\n",
    "\t\twrite_json(solution_list[i], \"svm_best_results.json\")\n",
    "\n",
    "\twith open(\"svm_best_results.json\", 'a') as f:\n",
    "\t\tf.write(\"]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaDepthSearch(data):\n",
    "\n",
    "\n",
    "\t## Clear the solution list and the accuracy list\n",
    "\tsolution_list.clear()\n",
    "\taccuracy_list.clear()\n",
    "\n",
    "\t## Create a variable to store the number of tests that have been preformed\n",
    "\titerationCount = 0\n",
    "\n",
    "\t## Calculate the number of tests which will be preformed\n",
    "\tnumber_of_tests = (\n",
    "\t\tlen(data['Estimator']['n_estimators']) *\n",
    "\t\tlen(data['Estimator']['criterion']) *\n",
    "\t\tlen(data['Estimator']['max_features']) *\n",
    "\t\tlen(data['Estimator']['bootstrap']) *\n",
    "\t\tlen(data['Estimator']['min_samples_split']) *\n",
    "\t\tlen(data['Estimator']['min_samples_leaf']) *\n",
    "\t\tlen(data['Params']['n_estimators']) *\n",
    "\t\tlen(data['Params']['learning_rate']) *\n",
    "\t\tlen(data['Params']['algorithim'])\n",
    "\t)\n",
    "\n",
    "\t## Set up the ada_results.json file to store the best solutions discovered by the tests\n",
    "\twith open(\"ada_results.json\", 'w') as f:\n",
    "\n",
    "\t\t## write the opening square bracket to the file to start the JSON array\n",
    "\t\tf.write(\"[\\n\")\n",
    "\t\t\n",
    "\n",
    "\t## Append an empty object to the solution list\n",
    "\tsolution_list.append(current_ada_data)\n",
    "\t## Set the accuracy to the worst possible metric score\n",
    "\taccuracy_list.append(0.0)\n",
    "\n",
    "\n",
    "\t## Itterate through the different parameters in the data dictionary relating to the Random Forest Classifier\n",
    "\tfor n_estimators in data['Estimator']['n_estimators']:\n",
    "\t\tfor criterion in data['Estimator']['criterion']:\n",
    "\t\t\tfor max_features in data['Estimator']['max_features']:\n",
    "\t\t\t\tfor bootstrap in data['Estimator']['bootstrap']:\n",
    "\t\t\t\t\tfor min_samples_split in data['Estimator']['min_samples_split']:\n",
    "\t\t\t\t\t\tfor min_samples_leaf in data['Estimator']['min_samples_leaf']:\n",
    "\t\t\t\t\t\t\t\n",
    "\n",
    "\t\t\t\t\t\t\t## Set the estimator dictionary to the current parameters indexed by the loop\n",
    "\t\t\t\t\t\t\tcurrent_ada_data['Estimator']['n_estimators'] = n_estimators\n",
    "\t\t\t\t\t\t\tcurrent_ada_data['Estimator']['criterion'] = criterion\n",
    "\t\t\t\t\t\t\tcurrent_ada_data['Estimator']['max_features'] = max_features\n",
    "\t\t\t\t\t\t\tcurrent_ada_data['Estimator']['bootstrap'] = bootstrap\n",
    "\t\t\t\t\t\t\tcurrent_ada_data['Estimator']['min_samples_split'] = min_samples_split\n",
    "\t\t\t\t\t\t\tcurrent_ada_data['Estimator']['min_samples_leaf'] = min_samples_leaf\n",
    "\n",
    "\n",
    "\t\t\t\t\t\t\t## Itterate through the different parameters in the data dictionary relating to the AdaBoost Classifier\n",
    "\t\t\t\t\t\t\tfor n_estimators_params in data['Params']['n_estimators']:\n",
    "\t\t\t\t\t\t\t\tfor learning_rate in data['Params']['learning_rate']:\n",
    "\t\t\t\t\t\t\t\t\tfor algorithim in data['Params']['algorithim']:\n",
    "\n",
    "\t\t\t\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t\t\t\t## Set the hyperparamaters dictionary to the current parameters indexed by the loop\n",
    "\t\t\t\t\t\t\t\t\t\tcurrent_ada_data['Params']['n_estimators'] = n_estimators_params\n",
    "\t\t\t\t\t\t\t\t\t\tcurrent_ada_data['Params']['learning_rate'] = learning_rate\n",
    "\t\t\t\t\t\t\t\t\t\tcurrent_ada_data['Params']['algorithim'] = algorithim\n",
    "\n",
    "\t\t\t\t\t\t\t\t\t\t## Create a new instance of the ada_model class with the current_ada_data dictionary\n",
    "\t\t\t\t\t\t\t\t\t\tcurrent_test = ada_model(current_ada_data)\n",
    "\n",
    "\t\t\t\t\t\t\t\t\t\t## Call the predict method of the current_test instance\n",
    "\t\t\t\t\t\t\t\t\t\tcurrent_test.predict()\n",
    "\t\t\t\t\t\t\t\t\t\t\n",
    "\n",
    "\t\t\t\t\t\t\t\t\t\t## Preform a comparison check\n",
    "\t\t\t\t\t\t\t\t\t\tcheck_worst(current_test, \"ada_results.json\")\n",
    "\n",
    "\t\t\t\t\t\t\t\t\t\t## Increment the iteration count\n",
    "\t\t\t\t\t\t\t\t\t\titerationCount += 1\n",
    "\t\t\t\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t\t\t## Write the current iteration count to the file to keep track of the progress EVERY TIME THE LEARNING_RATE IS CHANGED\n",
    "\t\t\t\t\t\t\t\t\twith open(\"ada_iterations.txt\", 'w') as f:\n",
    "\t\t\t\t\t\t\t\t\t\tf.write(\"Iteration: \" + str(iterationCount) + \"/\" + str(number_of_tests))\n",
    "\n",
    "\n",
    "\t## Write the closing square bracket to the file to end the JSON array\n",
    "\twith open(\"ada_results.json\", 'a') as f:\n",
    "\t\tf.write(\"]\\n\")\n",
    "\n",
    "\n",
    "\t## Write the best solutions to the output file\n",
    "\twith open(\"ada_best_results.json\", 'w') as f:\n",
    "\t\tf.write(\"[\\n\")\n",
    "\n",
    "\tfor i in range(len(solution_list)):\n",
    "\t\twrite_json(solution_list[i], \"ada_best_results.json\")\n",
    "\n",
    "\twith open(\"ada_best_results.json\", 'a') as f:\n",
    "\t\tf.write(\"]\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute the Search Algorithms\n",
    "\n",
    "These functions simply call the aforementioned search algorithms with the predefined list of hyperparamaters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svmDepthFirstSearch(svm_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaDepthSearch(ada_ensambles_tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Results into memory\n",
    "\n",
    "This is where the application reads the results of a previously completed search. It is important to note, this function does not load the newly created JSON files. Instead, it reads a finished test stored in a separated folder. This is to ensure that the previously learned solutions are not removed and can be reapplied in the future. Using the **JSON.load** method, its possible to easily translate a json array into a python Dictionary Array. This will make referencing much easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the array to store the solutions\n",
    "\n",
    "array_of_solutions = []\n",
    "\n",
    "def read_json(filepath):\n",
    "\t## Open the file in read mode\n",
    "\twith open(filepath, 'r') as f:\n",
    "\t\t## Load the JSON file into the array_of_solutions variable\n",
    "\t\treturn json.load(f)\n",
    "\n",
    "\n",
    "## Read the best results from the SVM model\n",
    "array_of_solutions = read_json(\"TestOutputsSVM\\soltuions320k.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Panda Restructure\n",
    "\n",
    "Creating a panda **DataFrame** automatically converts the data into columns and rows, like a standardised table of elements. This completed data structure should be much more readable to the operator and can then be used to make predictions about how the model could preform under the correct hyperparamaters. This then displays the 80 solutions found in the previous test. It may be apparent that the **solutions320k.json** file is formatted differently to the one produced by the grid search. This results datafile was generated before the **write_json** file was designed. This previous method resulted in poor readability and messy datastrcutures. The new method is much more streamlined, but converting the reading method for the svm_results would take some consideration.\n",
    "\n",
    "***@@**: This step is unnecessasary- it just helps to give an idea of the data to be processed, and gives a better understanding of how the proceeding functions handle said data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    kernel func_shape  shrinking  probability  tollerance  max_iter  C  \\\n",
      "0     poly        ovo       True         True      0.0002      1000  7   \n",
      "1     poly        ovo       True         True      0.0003      1000  7   \n",
      "2     poly        ovo       True         True      0.0004      1000  7   \n",
      "3     poly        ovo       True         True      0.0005      1000  7   \n",
      "4     poly        ovo       True         True      0.0006      1000  7   \n",
      "..     ...        ...        ...          ...         ...       ... ..   \n",
      "75  linear        ovo       True         True      0.0006      1303  7   \n",
      "76  linear        ovo       True         True      0.0007      1303  7   \n",
      "77  linear        ovo       True         True      0.0008      1303  7   \n",
      "78  linear        ovo       True         True      0.0009      1303  7   \n",
      "79  linear        ovo       True         True      0.0010      1303  7   \n",
      "\n",
      "    closed_accuracy  closed_precision  closed_recall  closed_f1  closed_fnr  \\\n",
      "0          0.740260          0.647059       0.600000   0.622642    0.400000   \n",
      "1          0.740260          0.647059       0.600000   0.622642    0.400000   \n",
      "2          0.740260          0.647059       0.600000   0.622642    0.400000   \n",
      "3          0.740260          0.647059       0.600000   0.622642    0.400000   \n",
      "4          0.740260          0.647059       0.600000   0.622642    0.400000   \n",
      "..              ...               ...            ...        ...         ...   \n",
      "75         0.772727          0.656250       0.763636   0.705882    0.236364   \n",
      "76         0.772727          0.656250       0.763636   0.705882    0.236364   \n",
      "77         0.772727          0.656250       0.763636   0.705882    0.236364   \n",
      "78         0.772727          0.656250       0.763636   0.705882    0.236364   \n",
      "79         0.772727          0.656250       0.763636   0.705882    0.236364   \n",
      "\n",
      "                                          closed_pred  \n",
      "0   [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, ...  \n",
      "1   [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, ...  \n",
      "2   [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, ...  \n",
      "3   [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, ...  \n",
      "4   [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, ...  \n",
      "..                                                ...  \n",
      "75  [0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, ...  \n",
      "76  [0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, ...  \n",
      "77  [0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, ...  \n",
      "78  [0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, ...  \n",
      "79  [0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, ...  \n",
      "\n",
      "[80 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "#frame the data into a pandas dataframe\n",
    "df = pd.DataFrame(array_of_solutions)\n",
    "\n",
    "#display the data\n",
    "print(df[0:80])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Helper Functions \n",
    "\n",
    "These functions, while simple in nature, allow for far cleaner code: overall, improving readability. Instead of needing to write these code blocks in-line, presenting them inside functions splits the code. This in tern helps to lessen the code's indentation, negating confusion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Results to Grid* Function\n",
    "\n",
    "These functions are designed to take the results from **read_json**, translating them into a dictionary with arrays corrisoponding to unique values for each paramater. \n",
    "\n",
    "They start by defining the dictionary for which to store the unique values, then itterating over each individaual entity in the results file. During itteration, each value is added to a list. Once this cycle has completed, a new dictionary is defined with the same keys. Lists are then converted into sets, removing any non-unique values, and finally converted back into lists for integrity. This final dictionary, filled with keys assosiated to unique lists is returned for later use. \n",
    "\n",
    "It should be worth noting that the outputs will **not** include the metrics produced by the model. These will not be needed for the proceeding functions. \n",
    "\n",
    "#### Paramaters:\n",
    "<div style=\"margin-left: 20px;\">\n",
    "\t<p>\n",
    "\t\t<strong>non_unique_values</strong> \t: This paramater is an array of dictionarys produced by the **read_json()** function. \n",
    "\t</p>\n",
    "</div>\n",
    "\n",
    "#### Returns:\n",
    "<div style=\"margin-left: 20px;\">\n",
    "\t<p>\n",
    "\t\t<strong>unique_dict</strong> \t: This variable is a Dictionary which stores all unique *best* inputs assosiated with the respected model.\n",
    "\t</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_results_to_grid(non_unique_values):\n",
    "\n",
    "\t## Create a dictionary to store the values of the non_unique_values dictionary\n",
    "\tsearch = {\n",
    "\t\t'kernel': [],\n",
    "\t\t'max_iter': [],\n",
    "\t\t'decision_function_shape': [],\n",
    "\t\t'probability': [],\n",
    "\t\t'shrinking': [],\n",
    "\t\t'C': [],\n",
    "\t\t'tollerance': [],\n",
    "\t}\n",
    "\n",
    "\t## Itterate through the non_unique_values dictionary\n",
    "\tfor i in range(len(non_unique_values)):\n",
    "\t\t## Append the values to the unique_search dictionary\n",
    "\t\tsearch['kernel'].append(non_unique_values[i]['features']['kernel'])\n",
    "\t\tsearch['max_iter'].append(non_unique_values[i]['features']['max_iter'])\n",
    "\t\tsearch['decision_function_shape'].append(non_unique_values[i]['features']['decision_function_shape'])\n",
    "\t\tsearch['probability'].append(non_unique_values[i]['features']['probability'])\n",
    "\t\tsearch['shrinking'].append(non_unique_values[i]['features']['shrinking'])\n",
    "\t\tsearch['C'].append(non_unique_values[i]['features']['C'])\n",
    "\t\tsearch['tollerance'].append(non_unique_values[i]['features']['tollerance'])\n",
    "\n",
    "\t## Create a dictionary to store the unique values of the unique_search dictionary\n",
    "\tunique_dict = {\n",
    "\t\t## Cast the lists to sets to remove duplicates and then cast them back to lists\n",
    "\t\t'kernel': list(set(search['kernel'])),\n",
    "\t\t'max_iter': list(set(search['max_iter'])),\n",
    "\t\t'decision_function_shape': list(set(search['decision_function_shape'])),\n",
    "\t\t'probability': list(set(search['probability'])),\n",
    "\t\t'shrinking': list(set(search['shrinking'])),\n",
    "\t\t'C': list(set(search['C'])),\n",
    "\t\t'tol': list(set(search['tollerance'])),\n",
    "\t}\n",
    "\n",
    "\t## Return the unique_dict\n",
    "\treturn unique_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ada_results_to_grid(non_unique_values):\n",
    "\n",
    "\t## Create a dictionary to store the values of the non_unique_values dictionary\n",
    "\tsearch = {\n",
    "\t\t'estimator': {\n",
    "\t\t\t\t\"n_estimators\": [],#int\n",
    "\t\t\t\t\"criterion\": [],#str\n",
    "\t\t\t\t\"max_features\": [],#str\n",
    "\t\t\t\t\"bootstrap\": [],#bool\n",
    "\t\t\t\t\"min_samples_split\": [],#int\n",
    "\t\t\t\t\"min_samples_leaf\": []#int\n",
    "\t\t\t},\n",
    "\t\t'params': {\n",
    "\t\t\t\t\"n_estimators\": [],#int\n",
    "\t\t\t\t\"learning_rate\": [],#float\n",
    "\t\t\t\t\"algorithim\": []#str\n",
    "\t\t\t}\n",
    "\t}\n",
    "\n",
    "\t## Itterate through the non_unique_values dictionary\n",
    "\tfor i in range(len(non_unique_values)):\n",
    "\n",
    "\t\t## Append the values to the unique_search dictionary\n",
    "\t\tsearch['estimator']['n_estimators'].append(non_unique_values[i]['Estimator']['n_estimators'])\n",
    "\t\tsearch['estimator']['criterion'].append(non_unique_values[i]['Estimator']['criterion'])\n",
    "\t\tsearch['estimator']['max_features'].append(non_unique_values[i]['Estimator']['max_features'])\n",
    "\t\tsearch['estimator']['bootstrap'].append(non_unique_values[i]['Estimator']['bootstrap'])\n",
    "\t\tsearch['estimator']['min_samples_split'].append(non_unique_values[i]['Estimator']['min_samples_split'])\n",
    "\t\tsearch['estimator']['min_samples_leaf'].append(non_unique_values[i]['Estimator']['min_samples_leaf'])\n",
    "\n",
    "\t\tsearch['params']['n_estimators'].append(non_unique_values[i]['Params']['n_estimators'])\n",
    "\t\tsearch['params']['learning_rate'].append(non_unique_values[i]['Params']['learning_rate'])\n",
    "\t\tsearch['params']['algorithim'].append(non_unique_values[i]['Params']['algorithim'])\n",
    "\n",
    "\t## Create a dictionary to store the unique values of the unique_search dictionary\n",
    "\tunique_dict = {\n",
    "\t\t'estimator': {\n",
    "\t\t\t\t## Cast the lists to sets to remove duplicates and then cast them back to lists\n",
    "\t\t\t\t\"n_estimators\": list(set(search['estimator']['n_estimators'])),#int\n",
    "\t\t\t\t\"criterion\": list(set(search['estimator']['criterion'])),#str\n",
    "\t\t\t\t\"max_features\": list(set(search['estimator']['max_features'])),#str\n",
    "\t\t\t\t\"bootstrap\": list(set(search['estimator']['bootstrap'])),#bool\n",
    "\t\t\t\t\"min_samples_split\": list(set(search['estimator']['min_samples_split'])),#int\n",
    "\t\t\t\t\"min_samples_leaf\": list(set(search['estimator']['min_samples_leaf']))#int\n",
    "\t\t\t},\n",
    "\t\t'params': {\n",
    "\t\t\t\t\"n_estimators\": list(set(search['params']['n_estimators'])),#int\n",
    "\t\t\t\t\"learning_rate\": list(set(search['params']['learning_rate'])),#float\n",
    "\t\t\t\t\"algorithim\": list(set(search['params']['algorithim']))#str\n",
    "\t\t\t}\n",
    "\t}\n",
    "\n",
    "\treturn unique_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small example code\n",
    "\n",
    "This example of how functions can be used, in conjunction, is desinged to quicly show the operator the absolute best values for each feature. \n",
    "\n",
    "Stepping through this line of code: In the center we are passing the path for the *svm search results*. This function, **read_json**, then returns a array holding all of the results generated from said search. This is passed to the **svm_results_to_grid** function which, aptly named, takes an array of Dictionary objects and translated them into unique arrays of values. This ensures features are not tested more than once.The final results are then passed to the standard JSON function, Dumps. This turns the data back into a JSON, giving a clean **print** statement without any string formatting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "        \"kernel\": [\n",
      "                \"linear\"\n",
      "        ],\n",
      "        \"max_iter\": [\n",
      "                3945,\n",
      "                4046,\n",
      "                2129,\n",
      "                4853,\n",
      "                6972\n",
      "        ],\n",
      "        \"decision_function_shape\": [\n",
      "                \"ovo\",\n",
      "                \"ovr\"\n",
      "        ],\n",
      "        \"probability\": [\n",
      "                false,\n",
      "                true\n",
      "        ],\n",
      "        \"shrinking\": [\n",
      "                false,\n",
      "                true\n",
      "        ],\n",
      "        \"C\": [\n",
      "                9,\n",
      "                11,\n",
      "                7\n",
      "        ],\n",
      "        \"tol\": [\n",
      "                0.04046363636363637,\n",
      "                0.06266363636363637,\n",
      "                0.07174545454545456,\n",
      "                0.09394545454545455,\n",
      "                0.009181818181818182,\n",
      "                0.031381818181818184,\n",
      "                0.0001,\n",
      "                0.07578181818181819,\n",
      "                0.0223,\n",
      "                0.05358181818181819,\n",
      "                0.08486363636363638,\n",
      "                0.09798181818181818,\n",
      "                0.044500000000000005,\n",
      "                0.013218181818181818,\n",
      "                0.03541818181818182,\n",
      "                0.06670000000000001,\n",
      "                0.0889,\n",
      "                0.004136363636363637,\n",
      "                0.026336363636363637,\n",
      "                0.057618181818181825,\n",
      "                0.07073636363636364,\n",
      "                0.04853636363636364,\n",
      "                0.07981818181818183,\n",
      "                0.09293636363636364,\n",
      "                0.017254545454545456,\n",
      "                0.03945454545454546,\n",
      "                0.008172727272727272,\n",
      "                0.030372727272727273,\n",
      "                0.06165454545454546,\n",
      "                0.08385454545454546,\n",
      "                0.05257272727272728,\n",
      "                0.021290909090909093,\n",
      "                0.06569090909090909,\n",
      "                0.043490909090909094,\n",
      "                0.07477272727272728,\n",
      "                0.09697272727272728,\n",
      "                0.012209090909090909,\n",
      "                0.0031272727272727272,\n",
      "                0.03440909090909092,\n",
      "                0.056609090909090914,\n",
      "                0.07880909090909091,\n",
      "                0.0878909090909091,\n",
      "                0.02532727272727273,\n",
      "                0.04752727272727273,\n",
      "                0.016245454545454546,\n",
      "                0.03844545454545455,\n",
      "                0.06972727272727273,\n",
      "                0.09192727272727273,\n",
      "                0.007163636363636364,\n",
      "                0.06064545454545455,\n",
      "                0.029363636363636366,\n",
      "                0.05156363636363637,\n",
      "                0.07376363636363636,\n",
      "                0.08284545454545456,\n",
      "                0.020281818181818182,\n",
      "                0.0112,\n",
      "                0.04248181818181819,\n",
      "                0.06468181818181819,\n",
      "                0.08688181818181819,\n",
      "                0.09596363636363638,\n",
      "                0.033400000000000006,\n",
      "                0.002118181818181818,\n",
      "                0.055600000000000004,\n",
      "                0.02431818181818182,\n",
      "                0.04651818181818182,\n",
      "                0.07780000000000001,\n",
      "                0.1,\n",
      "                0.015236363636363636,\n",
      "                0.03743636363636364,\n",
      "                0.05963636363636364,\n",
      "                0.006154545454545455,\n",
      "                0.06871818181818183,\n",
      "                0.08183636363636364,\n",
      "                0.09091818181818183,\n",
      "                0.028354545454545455,\n",
      "                0.01927272727272727,\n",
      "                0.05055454545454546,\n",
      "                0.07275454545454546,\n",
      "                0.09495454545454546,\n",
      "                0.01019090909090909,\n",
      "                0.04147272727272728,\n",
      "                0.032390909090909095,\n",
      "                0.05459090909090909,\n",
      "                0.06367272727272728,\n",
      "                0.07679090909090909,\n",
      "                0.08587272727272728,\n",
      "                0.0011090909090909092,\n",
      "                0.023309090909090908,\n",
      "                0.014227272727272727,\n",
      "                0.045509090909090916,\n",
      "                0.06770909090909091,\n",
      "                0.08990909090909091,\n",
      "                0.0989909090909091,\n",
      "                0.03642727272727273,\n",
      "                0.005145454545454546,\n",
      "                0.027345454545454544,\n",
      "                0.058627272727272736,\n",
      "                0.08082727272727273,\n",
      "                0.018263636363636364,\n",
      "                0.04954545454545455\n",
      "        ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(svm_results_to_grid(read_json(\"Assessment_Outputs\\svm_results.json\")), indent=8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Optimised Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Class\n",
    "\n",
    "Unlike the search classes, these were designed with inheritence. Any preprocessing of data happens in the extended class. There are three methods assosaiated with this class: The Constructor, Predict, and Print. Instead of the previous classes functionality of handling training and testing inside of the predict function, the training has been separated and moved to the constructor. \n",
    "\n",
    "Inside the **final_model.__init__** method, two key things happen. First the grid search is defined. This is a simple function-local variable and is not needed once the constructor has terminated: this helps to free useless memory. The **GridSearchCV** function had independent hardcoded variables and do not change inputs between the two extended classes. How they act, however, is vastly different. By leveraging the ability to pass variables to the constructor, it is possible to pass a classifier as a function paramater. This means code can be reused between extended classes without too many extra lines being added in the independent superclass. \n",
    "\n",
    "Next, the grid search is trained. This is where the simulations, passed to the function by the best_grid variable as a paramater, are ran. Each possible solution is scored using the defined **scoring** metric. Once the tests have concluded, the solution, which scored the best on the training data provided, will be stored in the class variable **estimator**. There, it can be easily referenced for multiple future predictions. The **best_paramaters** are also stored at this point. It gives the operator some guidance about how the current model is running, if they decide that knowing is crucial. This could occur in multiple instances, a common example would be to diagnose a problem with the Machine Learning algorithm. If the results are becoming unstable, it could be useful to see which hyper paramaters are being selected for the test- so that they may be excused from future models. \n",
    "\n",
    "It's important to consider, *the hardware these simulations ran on is signifigantly more powerful than what would be found in the common desktop in a hospital ward*. This being the case, at the algorithms height it only used **3.5GB of memory**, leaving a remaining 4.5GB out of the standard 8GB memory used in slightly older machines. The CPU was also maxed out, sitting at **99%** usage the duration of the simulations. It must be understood, without further testing *(ripping all relavent code into a standalone script)*, its difficult to tell how much of this memory usage can be atributed to the Python code itself. Another likely cause of some memory and CPU usage is the Jupyter and Visual Studio Code enviroment. \n",
    "\n",
    "While the CPU used is also much more powerful, *its worth noting that the number of cores, or frequency of the processor, **should not limit the algorithm's capability**. It may, however, take longer to process the training data.* Given it took this hardware **2 mins 5 seconds**, it would be *expected to take **at most 5minutes***. This is pure speculation, without direct access to the typical hardware info inside an NHS ward: the final time complexity is unknown. If hardware were to become known, virtual machines could be created to simulate the standard operating enviroment; giving better tests as to the hardware optimisation succession of the models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Constructor()***\n",
    "\n",
    "*Forceably called method on call entity creation. This is responsible for the setup of prediction.*\n",
    "\n",
    "#### Paramaters:\n",
    "\n",
    "<div style=\"margin-left: 20px;\">\n",
    "\t<p>\n",
    "\t\t<strong>training_data</strong> : This Dictonary is used to store a multi-dimensional list and a singular-dimension list. They should have respective keys named <strong>X_train</strong> and <strong>y_train</strong>. \n",
    "\t</p>\n",
    "\t<p>\n",
    "\t\t<strong>classifier</strong> : This should be a callable object or a variable which points to said object. An example would be the <strong>SVM Classifier</strong>.\n",
    "\t</p>\n",
    "\t\n",
    "</div>\n",
    "<hr style=\"width:50%;\" align=\"left\">\n",
    "\n",
    "### ***Predict()***\n",
    "\n",
    "*Function called to predict the outcomes of the **test_data**. It is also responsible for scoring the test inputs.*\n",
    "\n",
    "#### Paramaters:\n",
    "\n",
    "<div style=\"margin-left: 20px;\">\n",
    "\t<p>\n",
    "\t\t<strong>test_data</strong> : This Dictonary is used to store the range of hyper-paramaters passed to the depth first grid search.\n",
    "\t</p>\n",
    "\t\n",
    "</div>\n",
    "<hr style=\"width:50%;\" align=\"left\">\n",
    "\n",
    "\n",
    "### ***Print()***\n",
    "\n",
    "*This function **does not take any paramaters**, it is simply designed to print all relavent data to the outcome of the final solution.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of base class for the final models\n",
    "class final_model:\n",
    "\n",
    "\t## Constructor - Takes in the training data and the classifier to be used\n",
    "\tdef __init__(self, training_data, classifier):\n",
    "\n",
    "\t\t### Create the grid search model with the given parameters from the constructor\n",
    "\t\tgridSearch = GridSearchCV( \n",
    "\t\t\t\tclassifier, ### this variable is passed directly from the constructor\n",
    "\t\t\t\tself.best_grid, ### this variable is defined in the child class\n",
    "\t\t\t\tn_jobs=-1, \n",
    "\t\t\t\tverbose=2,\n",
    "\t\t\t\tcv=3,\n",
    "\t\t\t\tscoring='roc_auc_ovo_weighted'\n",
    "\t\t\t)\n",
    "\n",
    "\n",
    "\t\t### Fit the model to the training data\n",
    "\t\tgridSearch.fit(training_data['X_train'], training_data['y_train'])\n",
    "\n",
    "\n",
    "\t\t### Assign the best parameters and the best estimator to the class variables\n",
    "\t\tself.best_params = gridSearch.best_params_\n",
    "\t\tself.estimator = gridSearch.best_estimator_\n",
    "\n",
    "\n",
    "\t## Predict Function - Uses the best estimator from the constructor to predict the outcome of the test data\n",
    "\tdef predict(self, test_data):\n",
    "\n",
    "\t\t### Predict the outcome of the test data\n",
    "\t\tself.closed_prediction = self.estimator.predict(test_data['X_test'])\n",
    "\n",
    "\t\t### Assign the test data to the class variables - this is used to calculate the metrics of the model and for data percistance after function execution.\n",
    "\t\tself.y_test = test_data['y_test']\n",
    "\n",
    "\t\t### Calculate the accuracy, f1 score, false negative rate, recall, precision, and specificity of the model\n",
    "\t\tself.closed_accuracy = accuracy_score(y_test, self.closed_prediction)\n",
    "\t\tself.closed_f1 = f1_score(y_test, self.closed_prediction)\n",
    "\t\tself.closed_fnr, self.closed_recall, self.closed_precision, self.closed_specificity = ratios(y_test, self.closed_prediction)\n",
    "\n",
    "\t\t### Create the confusion matrix of the model to be used for visualisation\n",
    "\t\tself.cm = confusion_matrix(y_test, self.closed_prediction, labels=[0, 1])\n",
    "\n",
    "\n",
    "\t## Print Function - Prints the metrics of the model and the confusion matrix\n",
    "\tdef print(self):\n",
    "\t\t\n",
    "\t\t### Print the metrics of the model\n",
    "\t\tprint(\"Accuracy: \", self.closed_accuracy)\n",
    "\t\tprint(\"F1: \", self.closed_f1)\n",
    "\t\tprint(\"FNR: \", self.closed_fnr)\n",
    "\t\tprint(\"Recall: \", self.closed_recall)\n",
    "\t\tprint(\"Precision: \", self.closed_precision)\n",
    "\t\tprint(\"Specificity: \", self.closed_specificity)\n",
    "\n",
    "\t\tprint(\"Confusion Matrix: \\n\", self.cm)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimised SVM Model\n",
    "\n",
    "Inside the constructor of the **SMV Model**, the best grid is defined and so is the classifier. For this Child, it should be SVC. This is then passed directly to the Parent classes constructor for initilisation. It should be noted, as previously mentioned: *SVC algorithms assume that data is centered around a mean of 0*. This means the data must be standardised before it can be used. *To prevent an operator from accidently forgetting this step, the data is standardised inside the Child's overwritten functions*, then passed to the Parents origonal function with **complete variables ready for processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class final_svm_model(final_model):\n",
    "\n",
    "\tdef __init__(self, best_grid, training_data):\n",
    "\n",
    "\t\tself.best_grid = best_grid\n",
    "\n",
    "\t\tclassifier = SVC()\n",
    "\n",
    "\t\tself.scaler = StandardScaler()\n",
    "\t\ttraining_data['X_train'] = self.scaler.fit_transform(training_data['X_train'])\n",
    "\n",
    "\t\tsuper().__init__(training_data, classifier)\n",
    "\n",
    "\n",
    "\tdef predict(self, test_data):\n",
    "\n",
    "\t\ttest_data['X_test'] = self.scaler.transform(test_data['X_test'])\n",
    "\n",
    "\t\treturn super().predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimised Ada Model\n",
    "\n",
    "Similarly to the **Optimised SVM Model**, the Ada Model builds from the *standard **final_model** base class*. Instead of standardising the data to fit the expectations of the model, it is possible to simply pass the feature values directly. This is because the *RandomForest classifier* does not assume a relative mean on 0. It is, however, designed to build on the relative difference between two nodes on a tree. This means the only thing that needs to happen in the super class: the *definition of **best_grid** and definition of the **classifier***. As mentioned, storing the best_grid in this way allows it to be easily used in the Parent Constructor and later referenced. \n",
    "\n",
    "Next, the classifier is defined. The chosen configuation here is **AdaBoost Classifier** and **RandomForest Classifier**. These will be used with the *random_state* paramater, meaning every simulation preformed will use the same random sample locations. This keeps the search a ***fair test*** as there is no question to weather the resluts were because of a more preferable starting position. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class final_ada_model(final_model):\n",
    "\t\n",
    "\tdef __init__(self, best_grid, training_data):\n",
    "\n",
    "\t\tself.best_grid = best_grid\n",
    "\n",
    "\t\tclassifier = AdaBoostClassifier(\n",
    "\t\t\t\t\t\t\testimator=RandomForestClassifier(),\n",
    "\t\t\t\t\t\t\trandom_state=1\n",
    "\t\t\t\t\t\t)\n",
    "\n",
    "\t\tsuper().__init__(training_data, classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Optimised Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = {'X_train': X_train, 'y_train': y_train}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Optimised SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12000 candidates, totalling 36000 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m results_grid \u001b[38;5;241m=\u001b[39m svm_results_to_grid(read_json(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAssessment_Outputs\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msvm_results.json\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      2\u001b[0m training_data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_train\u001b[39m\u001b[38;5;124m'\u001b[39m: X_train, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_train\u001b[39m\u001b[38;5;124m'\u001b[39m: y_train}\n\u001b[1;32m----> 4\u001b[0m new_svm \u001b[38;5;241m=\u001b[39m \u001b[43mfinal_svm_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[59], line 12\u001b[0m, in \u001b[0;36mfinal_svm_model.__init__\u001b[1;34m(self, best_grid, training_data)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m     10\u001b[0m training_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_train\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mfit_transform(training_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_train\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[58], line 15\u001b[0m, in \u001b[0;36mfinal_model.__init__\u001b[1;34m(self, training_data, classifier)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, training_data, classifier):\n\u001b[0;32m      6\u001b[0m \tgridSearch \u001b[38;5;241m=\u001b[39m GridSearchCV( \u001b[38;5;66;03m# Create the SVC model with the given parameters from the current_svm_test dictionary\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \t\t\tclassifier,\n\u001b[0;32m      8\u001b[0m \t\t\t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_grid,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \t\t\tscoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc_ovo_weighted\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     13\u001b[0m \t\t)\n\u001b[1;32m---> 15\u001b[0m \t\u001b[43mgridSearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mX_train\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my_train\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_params \u001b[38;5;241m=\u001b[39m gridSearch\u001b[38;5;241m.\u001b[39mbest_params_\n\u001b[0;32m     18\u001b[0m \t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator \u001b[38;5;241m=\u001b[39m gridSearch\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32mc:\\Users\\Spoon\\miniconda3\\envs\\ML_SK\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Spoon\\miniconda3\\envs\\ML_SK\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Spoon\\miniconda3\\envs\\ML_SK\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1419\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Spoon\\miniconda3\\envs\\ML_SK\\lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Spoon\\miniconda3\\envs\\ML_SK\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Spoon\\miniconda3\\envs\\ML_SK\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\Spoon\\miniconda3\\envs\\ML_SK\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\Spoon\\miniconda3\\envs\\ML_SK\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Spoon\\miniconda3\\envs\\ML_SK\\lib\\concurrent\\futures\\_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 439\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\Spoon\\miniconda3\\envs\\ML_SK\\lib\\threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 302\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    303\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results_grid = svm_results_to_grid(read_json(\"Assessment_Outputs\\svm_results.json\"))\n",
    "\n",
    "new_svm = final_svm_model(results_grid, training_data)\n",
    "\n",
    "# new_svm = final_svm_model(svm_results_to_grid(read_json(\"Assessment_Outputs\\svm_results.json\")), {'X_train': X_train, 'y_train': y_train})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Optimised AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "new_svm = final_svm_model(results_grid, training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_svm.predict({'X_test': X_test, 'y_test': y_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing Optimised Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(cm, title, fig=None, ax=None):\n",
    "\t\n",
    "\tsns.heatmap(cm, ax=ax, annot=True, fmt='g', cmap='cividis', cbar=True)\n",
    "\n",
    "\n",
    "\tif(fig == None):\n",
    "\t\tplt.title('CONFUSION MATRIX FOR THE ' + title + ' MODEL')\n",
    "\t\tplt.text(0.5, 0.5, \"\\n\\nTrue Negative\", ha='center', va='center')\n",
    "\t\tplt.text(1.5, 0.5, \"\\n\\nFalse Positive\", ha='center', va='center')\n",
    "\t\tplt.text(0.5, 1.5, \"\\n\\nFalse Negative\", ha='center', va='center')\n",
    "\t\tplt.text(1.5, 1.5, \"\\n\\nTrue Positive\", ha='center', va='center')\n",
    "\n",
    "\t\tplt.xticks([0.5, 1.5], ['Negative', 'Positive'])\n",
    "\t\tplt.yticks([0.5, 1.5], ['Negative', 'Positive'])\n",
    "\n",
    "\t\tplt.ylabel('Actual')\n",
    "\t\tplt.xlabel('Predicted')\n",
    "\n",
    "\t\tplt.show()\n",
    "\telse:\n",
    "\t\tax.set_title('CONFUSION MATRIX FOR THE ' + title + ' MODEL')\n",
    "\t\tax.text(0.5, 0.5, \"\\n\\nTrue Negative\", ha='center', va='center')\n",
    "\t\tax.text(1.5, 0.5, \"\\n\\nFalse Positive\", ha='center', va='center')\n",
    "\t\tax.text(0.5, 1.5, \"\\n\\nFalse Negative\", ha='center', va='center')\n",
    "\t\tax.text(1.5, 1.5, \"\\n\\nTrue Positive\", ha='center', va='center')\n",
    "\n",
    "\t\tax.set_xticks([0.5, 1.5])\n",
    "\t\tax.set_xticklabels(['Negative', 'Positive'])\n",
    "\t\tax.set_yticks([0.5, 1.5])\n",
    "\t\tax.set_yticklabels(['Negative', 'Positive'])\n",
    "\n",
    "\t\tax.set_ylabel('Actual')\n",
    "\t\tax.set_xlabel('Predicted')\n",
    "\n",
    "\t\tfig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Unconfusing Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_unconfusing_matrix(cm, title, fig=None, ax=None):\n",
    "\n",
    "\tucm = np.array([[cm[0][1], cm[1][0]], [cm[1][1], cm[0][0]]])\n",
    "\t\n",
    "\tsns.heatmap(ucm, ax=ax, annot=True, fmt='g', cmap='cividis', cbar=True)\n",
    "\n",
    "\tif(fig == None):\n",
    "\n",
    "\t\tplt.title('UNCONFUSING MATRIX FOR THE ' + title + ' MODEL')\n",
    "\n",
    "\n",
    "\t\tplt.text(0.5, 0.5, \"\\n\\nFalse Positive\", ha='center', va='center')\n",
    "\t\tplt.text(1.5, 0.5, \"\\n\\nFalse Negative\", ha='center', va='center')\n",
    "\t\tplt.text(0.5, 1.5, \"\\n\\nTrue Positive\", ha='center', va='center')\n",
    "\t\tplt.text(1.5, 1.5, \"\\n\\nTrue Negative\", ha='center', va='center')\n",
    "\n",
    "\t\tplt.xticks([0.5, 1.5], ['Positive', 'Negative'])\n",
    "\t\tplt.yticks([0.5, 1.5], ['False', 'True'])\n",
    "\n",
    "\t\tplt.ylabel('Actual')\n",
    "\t\tplt.xlabel('Predicted')\n",
    "\n",
    "\t\tplt.show()\n",
    "\telse:\n",
    "\n",
    "\t\tax.set_title('UNCONFUSING MATRIX FOR THE ' + title + ' MODEL')\n",
    "\n",
    "\t\tax.text(0.5, 0.5, \"\\n\\nFalse Positive\", ha='center', va='center')\n",
    "\t\tax.text(1.5, 0.5, \"\\n\\nFalse Negative\", ha='center', va='center')\n",
    "\t\tax.text(0.5, 1.5, \"\\n\\nTrue Positive\", ha='center', va='center')\n",
    "\t\tax.text(1.5, 1.5, \"\\n\\nTrue Negative\", ha='center', va='center')\n",
    "\n",
    "\t\tax.set_xticks([0.5, 1.5])\n",
    "\t\tax.set_xticklabels(['Positive', 'Negative'])\n",
    "\t\tax.set_yticks([0.5, 1.5])\n",
    "\t\tax.set_yticklabels(['False', 'True'])\n",
    "\n",
    "\t\tfig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show both Matricies as subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_matrixs(cm, title):\n",
    "\n",
    "\tfig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "\tshow_confusion_matrix(cm, title, fig, ax[0])\n",
    "\tshow_unconfusing_matrix(cm, title, fig, ax[1])\n",
    "\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Spoon\\AppData\\Local\\Temp\\ipykernel_8772\\3143736730.py:35: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n",
      "C:\\Users\\Spoon\\AppData\\Local\\Temp\\ipykernel_8772\\518783969.py:42: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7532467532467533\n",
      "F1:  0.6545454545454545\n",
      "FNR:  0.34545454545454546\n",
      "Recall:  0.6545454545454545\n",
      "Precision:  0.6545454545454545\n",
      "Specificity:  0.8080808080808081\n",
      "Confusion Matrix: \n",
      " [[80 19]\n",
      " [19 36]]\n"
     ]
    }
   ],
   "source": [
    "show_matrixs(new_svm.cm, 'SVM')\n",
    "\n",
    "new_svm.print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_SK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
