{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score, precision_score, f1_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratios(y_true, y_pred):\n",
    "    # Get the confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "    \n",
    "    # Calculate False Negative Ratio\n",
    "    fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "    \n",
    "\t# Calculate Recall\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    \n",
    "\t# Calculate Precision\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    \n",
    "\t# Calculate specificity\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    \n",
    "    return fnr, recall, precision, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "5            5      116             74              0        0  25.6   \n",
      "6            3       78             50             32       88  31.0   \n",
      "7           10      115              0              0        0  35.3   \n",
      "8            2      197             70             45      543  30.5   \n",
      "9            8      125             96              0        0   0.0   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.627   50        1  \n",
      "1                     0.351   31        0  \n",
      "2                     0.672   32        1  \n",
      "3                     0.167   21        0  \n",
      "4                     2.288   33        1  \n",
      "5                     0.201   30        0  \n",
      "6                     0.248   26        1  \n",
      "7                     0.134   29        0  \n",
      "8                     0.158   53        1  \n",
      "9                     0.232   54        1  \n",
      "(768, 9)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "print(data[:10])\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "##split the data into training and testing data\n",
    "X = data.drop('Outcome', axis=1)\n",
    "y = data['Outcome']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_possibilitys = {\n",
    "\t'Class': {\n",
    "\t\t'n_estimators': np.linspace(1, 200, 10).astype(int),\n",
    "\t\t'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "\t\t'max_features': ['sqrt', 'log2'],\n",
    "\t\t'bootstrap': [True, False],\n",
    "\t\t'min_samples_split': np.linspace(2, 11, 10).astype(int),\n",
    "\t\t'min_samples_leaf': np.linspace(2, 6, 5).astype(int)\n",
    "\t},\n",
    "\t'Params': {\n",
    "\t\t'n_estimators': np.linspace(1, 100, 10).astype(int),\n",
    "\t\t'learning_rate': np.linspace(0.1, 3, 10),\n",
    "\t\t'algorithim': ['SAMME', 'SAMME.R']\n",
    "\t}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_test = {\n",
    "\t'clf': RandomForestClassifier,\n",
    "\t'clf_params': {},\n",
    "\t'params': {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "iteration_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test:\n",
    "\tdef __init__(self, current_test):\n",
    "\t\tself.hype_clf = current_test['clf'](\n",
    "\t\t\t\t\t\t\t\t\tn_estimators=current_test['clf_params']['n_estimators'], \n",
    "\t\t\t\t\t\t\t\t\tcriterion=current_test['clf_params']['criterion'],\n",
    "\t\t\t\t\t\t\t\t\tmax_features=current_test['clf_params']['max_features'], \n",
    "\t\t\t\t\t\t\t\t\tbootstrap=current_test['clf_params']['bootstrap'],\n",
    "\t\t\t\t\t\t\t\t\tmin_samples_split=current_test['clf_params']['min_samples_split'], \n",
    "\t\t\t\t\t\t\t\t\tmin_samples_leaf=current_test['clf_params']['min_samples_leaf'], \n",
    "\t\t\t\t\t\t\t\t\tn_jobs=-1\n",
    "\t\t\t\t\t\t\t\t)\n",
    "\t\t\t\n",
    "\t\t\n",
    "\t\tself.clf = AdaBoostClassifier(\n",
    "\t\t\t\t\t\t\tself.hype_clf,\n",
    "\t\t\t\t\t\t\tn_estimators=current_test['params']['n_estimators'],\n",
    "\t\t\t\t\t\t\tlearning_rate=current_test['params']['learning_rate'],\n",
    "\t\t\t\t\t\t\talgorithm=current_test['params']['algorithim'],\n",
    "\t\t\t\t\t\t\trandom_state=1)\n",
    "\t\t\n",
    "\t\tself.clf.fit(X_train, y_train)\n",
    "\t\tself.predsy_pred = self.clf.predict(X_test)\n",
    "\n",
    "\t\tself.fnr, self.recall, self.precision, self.specificity = ratios(y_test, self.predsy_pred)\n",
    "\t\tself.accuracy = accuracy_score(y_test, self.predsy_pred)\n",
    "\t\tself.f1 = f1_score(y_test, self.predsy_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_best(current_test):\n",
    "\n",
    "\tif (current_test.accuracy > 0.7):\n",
    "\t\n",
    "\t\tif current_test.accuracy > accuracy_list[0]:\n",
    "\t\t\tsolution_list.append(current_test)\n",
    "\t\t\taccuracy_list.append(current_test.accuracy)\n",
    "\n",
    "\t\t\tprint(\"New best solution found: \", current_test.accuracy)\n",
    "\n",
    "\t\t\twith open('ada_best_params.txt', 'a') as f:\n",
    "\t\t\t\tf.write(str(current_test.__dict__) + \",\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\t\t\tif(len(solution_list) > 10):\n",
    "\t\t\t\tsolution_list.pop(0)\n",
    "\t\t\t\taccuracy_list.pop(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tests:  1200000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best solution found:  0.7662337662337663\n",
      "New best solution found:  0.7012987012987013\n",
      "New best solution found:  0.7467532467532467\n",
      "New best solution found:  0.7207792207792207\n",
      "New best solution found:  0.7532467532467533\n",
      "New best solution found:  0.7337662337662337\n",
      "New best solution found:  0.7012987012987013\n",
      "New best solution found:  0.7077922077922078\n",
      "New best solution found:  0.7532467532467533\n",
      "New best solution found:  0.7662337662337663\n",
      "New best solution found:  0.7727272727272727\n",
      "New best solution found:  0.7142857142857143\n",
      "New best solution found:  0.7532467532467533\n",
      "New best solution found:  0.7467532467532467\n",
      "New best solution found:  0.7792207792207793\n",
      "New best solution found:  0.7402597402597403\n",
      "New best solution found:  0.7077922077922078\n",
      "New best solution found:  0.7532467532467533\n",
      "New best solution found:  0.7597402597402597\n",
      "New best solution found:  0.7792207792207793\n",
      "New best solution found:  0.7792207792207793\n",
      "New best solution found:  0.7272727272727273\n",
      "New best solution found:  0.7792207792207793\n",
      "New best solution found:  0.7597402597402597\n",
      "New best solution found:  0.8051948051948052\n",
      "New best solution found:  0.7597402597402597\n",
      "New best solution found:  0.7727272727272727\n",
      "New best solution found:  0.7597402597402597\n",
      "New best solution found:  0.7792207792207793\n",
      "New best solution found:  0.8051948051948052\n",
      "New best solution found:  0.8051948051948052\n",
      "New best solution found:  0.7402597402597403\n",
      "New best solution found:  0.8051948051948052\n",
      "New best solution found:  0.7727272727272727\n",
      "New best solution found:  0.8181818181818182\n",
      "New best solution found:  0.7662337662337663\n",
      "New best solution found:  0.7922077922077922\n",
      "New best solution found:  0.7727272727272727\n",
      "New best solution found:  0.7857142857142857\n",
      "New best solution found:  0.8116883116883117\n",
      "New best solution found:  0.8116883116883117\n",
      "New best solution found:  0.7467532467532467\n",
      "New best solution found:  0.8116883116883117\n",
      "New best solution found:  0.8116883116883117\n"
     ]
    }
   ],
   "source": [
    "total_tests = (\n",
    "\tlen(test_possibilitys['Class']['n_estimators']) * \n",
    "\tlen(test_possibilitys['Class']['criterion']) * \n",
    "\tlen(test_possibilitys['Class']['max_features']) * \n",
    "\tlen(test_possibilitys['Class']['bootstrap']) * \n",
    "\tlen(test_possibilitys['Class']['min_samples_split']) * \n",
    "\tlen(test_possibilitys['Class']['min_samples_leaf']) * \n",
    "\tlen(test_possibilitys['Params']['n_estimators']) * \n",
    "\tlen(test_possibilitys['Params']['learning_rate']) * \n",
    "\tlen(test_possibilitys['Params']['algorithim'])\n",
    ")\n",
    "print(\"Total Tests: \", total_tests)\n",
    "\n",
    "\n",
    "\n",
    "solution_list.append(current_test)\n",
    "accuracy_list.append(0.0)\n",
    "\n",
    "with open('ada_best_params.txt', 'w') as f:\n",
    "\tf.write(\"[\\n\")\n",
    "\n",
    "\n",
    "for _n_estimators in test_possibilitys['Class']['n_estimators']:\n",
    "\tfor _citeration in test_possibilitys['Class']['criterion']:\n",
    "\t\tfor _max_features in test_possibilitys['Class']['max_features']:\n",
    "\t\t\tfor _bootstrap in test_possibilitys['Class']['bootstrap']:\n",
    "\t\t\t\tfor _min_samples_split in test_possibilitys['Class']['min_samples_split']:\n",
    "\t\t\t\t\tfor _min_samples_leaf in test_possibilitys['Class']['min_samples_leaf']:\n",
    "\n",
    "\n",
    "\t\t\t\t\t\t#Test the hyper paramaters of the estimator\n",
    "\t\t\t\t\t\tcurrent_test['clf_params']['n_estimators'] = _n_estimators\n",
    "\t\t\t\t\t\tcurrent_test['clf_params']['criterion'] = _citeration\n",
    "\t\t\t\t\t\tcurrent_test['clf_params']['max_features'] = _max_features\n",
    "\t\t\t\t\t\tcurrent_test['clf_params']['bootstrap'] = _bootstrap\n",
    "\t\t\t\t\t\tcurrent_test['clf_params']['min_samples_split'] = _min_samples_split\n",
    "\t\t\t\t\t\tcurrent_test['clf_params']['min_samples_leaf'] = _min_samples_leaf\n",
    "\n",
    "\n",
    "\t\t\t\t\t\tfor _ada_estimator in test_possibilitys['Params']['n_estimators']:\n",
    "\t\t\t\t\t\t\tfor _ada_learning_rate in test_possibilitys['Params']['learning_rate']:\n",
    "\t\t\t\t\t\t\t\tfor _ada_algorithm in test_possibilitys['Params']['algorithim']:\n",
    "\n",
    "\n",
    "\t\t\t\t\t\t\t\t\t#Test the hyper paramaters of the estimator\n",
    "\t\t\t\t\t\t\t\t\tcurrent_test['params']['n_estimators'] = _ada_estimator\n",
    "\t\t\t\t\t\t\t\t\tcurrent_test['params']['learning_rate'] = _ada_learning_rate\n",
    "\t\t\t\t\t\t\t\t\tcurrent_test['params']['algorithim'] = _ada_algorithm\n",
    "\n",
    "\t\t\t\t\t\t\t\t\t#Test the model\n",
    "\t\t\t\t\t\t\t\t\tIterationTest = test(current_test)\n",
    "\t\t\t\t\t\t\t\t\tcheck_best(IterationTest)\n",
    "\n",
    "\t\t\t\t\t\t\t\t\titeration_count += 1\n",
    "\t\t\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\twith open('ada_iterations.txt', 'w') as f:\n",
    "\t\t\t\t\t\t\tf.write(str(iteration_count) + \"/\" + str(total_tests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77235772 0.79674797 0.7398374  0.74796748 0.78688525]\n",
      "Accuracy: 0.7402597402597403\n",
      "Confusion matrix:\n",
      "[[79 20]\n",
      " [20 35]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80        99\n",
      "           1       0.64      0.64      0.64        55\n",
      "\n",
      "    accuracy                           0.74       154\n",
      "   macro avg       0.72      0.72      0.72       154\n",
      "weighted avg       0.74      0.74      0.74       154\n",
      "\n",
      "Recall: 0.6363636363636364\n",
      "Precision: 0.6363636363636364\n",
      "F1 Score: 0.6363636363636364\n"
     ]
    }
   ],
   "source": [
    "hyp_clf = RandomForestClassifier()\n",
    "\n",
    "clf = AdaBoostClassifier(hyp_clf,\n",
    "    n_estimators=100, learning_rate=2)\n",
    "\n",
    "\n",
    "# the train-test split is done in each iteration of cross validation\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "print(scores)\n",
    "#find the input features that are most important\n",
    "\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, predictions)\n",
    "confusion = confusion_matrix(y_test, predictions)\n",
    "\n",
    "print('Accuracy:', acc)\n",
    "print('Confusion matrix:')\n",
    "print(confusion)\n",
    "\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "print('Recall:', recall_score(y_test, predictions))\n",
    "print('Precision:', precision_score(y_test, predictions))\n",
    "print('F1 Score:', f1_score(y_test, predictions))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_SK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
